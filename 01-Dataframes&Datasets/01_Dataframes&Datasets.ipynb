{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b3db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneyi import edelim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da5a3e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/states.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# read_csv() -> CSV formatındaki veri setini dataframe formatında import sağlayan pandas metodu.\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m states \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../data/states.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:678\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    663\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    664\u001B[0m     dialect,\n\u001B[0;32m    665\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    674\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    675\u001B[0m )\n\u001B[0;32m    676\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 678\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:932\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    929\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    931\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1216\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1212\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1213\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[0;32m   1214\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[0;32m   1215\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[1;32m-> 1216\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[0;32m   1217\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1225\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1226\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1227\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:786\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    783\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    785\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 786\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    787\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    788\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    793\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    794\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    795\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/states.csv'"
     ]
    }
   ],
   "source": [
    "# read_csv() -> CSV formatındaki veri setini dataframe formatında import sağlayan pandas metodu.\n",
    "states = pd.read_csv(\"../data/states.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"states\" dataframe'ini inceleyelim.\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5fbaf3",
   "metadata": {},
   "source": [
    "***\n",
    "## King County Ev Satış Dataseti\n",
    "This dataset includes the home sales from 2014-2015 in King County, WA (the county Seattle is located in)\n",
    "* `id` - house's unique id\n",
    "* `date` - sale date\n",
    "* `price` - sale price\n",
    "* `bedrooms` - number of bedrooms\n",
    "* `bathrooms` - numbers of bathrooms\n",
    "* `sqft_living` - living space square footage \n",
    "* `sqft_lot` - total lot square footage\n",
    "* `floors` - numbers of floors\n",
    "* `waterfront` - is the house waterfront (1) or not (0)\n",
    "* `view` - rating from 0 to 4 of how good the view from the house is\n",
    "* `condition` - rating from 1 (poor) to 5 (very good) of the condition of the house\n",
    "* `grade` - rating from 1-13 representing the construction quality of improvements. 1-3 Falls short of minimum building standards (cabins, etc.) 7 is avg grade, 11-13 have high-quality design & construction\n",
    "* `sqft_above` - square footage of the interior that is above ground level\n",
    "* `sqft_basement` - square footage of the interior that is below ground level\n",
    "* `yr_built` - year the house was initially built\n",
    "* `yr_renovated` - The year of the house’s last renovation (if any)\n",
    "* `zipcode` - zipcode that the house is located in\n",
    "* `lat` - the property's latitude\n",
    "* `long` - the property's longitude\n",
    "* `sqft_living15` - average interior space square footage of the nearest 15 neighbors\n",
    "* `sqft_lot15` - average lot square footage of the nearest 15 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb70555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ev bilgilerinin bulunduğu verisetini import edelim.\n",
    "houses = pd.read_csv(\"../data/kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c6c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas kütüphanesi, eğer büyük boyutlu bir veri ile çalışıyorsak bize bütün satır ve sütun değerlerini göstermez\n",
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7435786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# houeses dataframe'inin sütunlarını inceleyelim\n",
    "houses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c19097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# states dataframe'inin sütunlarını inceleyelim\n",
    "states.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec389d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len() metodu -> dataframe içerisindeki satır sayısını verir.\n",
    "len(houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1df5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape -> satır ve sütun sayısını verir\n",
    "# houses dataframe'inin satır ve sütun sayısını öğrenelim\n",
    "houses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size -> Satır Sayısı x Sütun Sayısı\n",
    "# houses dataframe'inin boyutunu öğrenelim\n",
    "houses.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076729ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# İlk 100 satırı görebilmek için min_rows attribute'u üzerinde manipülasyon yapıyoruz.\n",
    "pd.options.display.min_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0bd7e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Gerçekleştirdiğimiz manipülasyonun ardından houses dataframe'ini yeniden inceleyelim.\n",
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ed237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görmek istediğimiz satır sayısını 15 yapalım\n",
    "pd.options.display.min_rows = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head() metodu, default olarak dataframe'in ilk beş satırını görmemizi sağlar.\n",
    "first_5 = houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931077ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(first_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6094f0ae",
   "metadata": {},
   "source": [
    "* Son 4 hücredeki işlemlere bakarak, head() metodunun geriye bir DataFrame döndürdüğünü anlayabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_10 = houses.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6caef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_200 = houses.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad868f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head() metodu, default olarak dataframe'in ilk beş satırını görmemizi sağlar.\n",
    "last_5 = houses.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a7c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_9 = houses.tail(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f657a696",
   "metadata": {},
   "source": [
    "***\n",
    "**Hem head() metodu hem de tail() metodu yeni bir DataFrame döndürür ve her ikisinin de default parametresi 5'tir.**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbae95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info() metodu, üzerinde çalıştığımız dataframe hakkında bazı bilgileri elde edebilmemizi sağlayan metot.\n",
    "# houses dataframe'i içeriindeki sütunların barındığı verilerin türünü ve sayısını inceleyelim.\n",
    "houses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "states.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3497a2d",
   "metadata": {},
   "source": [
    "* Pandas, `string` tipindeki değişkenleri iki şekilde tutar:\n",
    "    1. `object` veri tipi olarak ki bu tip stringler başta olmak üzere bütün Python objelerini kapsar.\n",
    "    1. `StringDtype` tipinde tutar ki bu tip adından da anlaşılacağı üzere string tipindeki değişkenlere özeldir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0302e31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dtypes, Sütunların tuttuğu verilerin veri tipini öğrenmemizi sağlar.\n",
    "# houses dataframe'i içeriindeki sütunların barındığı verilerin türünü inceleyelim.\n",
    "houses.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13421b21",
   "metadata": {},
   "source": [
    "***\n",
    "## Titanic Dataset İncelemesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic veri setini import edelim.\n",
    "titanic = pd.read_csv(\"../data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a590a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic dataframe'inin ilk beş örneğini inceleyelim.\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e9d806",
   "metadata": {},
   "source": [
    "### Feature'lar\n",
    "\n",
    "* `pclass` - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "* `survived` - Survival (0 = No; 1 = Yes)\n",
    "* `name` - Name\n",
    "* `sex` - Sex\n",
    "* `age` - Age\n",
    "* `sibsp` - Number of Siblings/Spouses Aboard\n",
    "* `parch` - Number of Parents/Children Aboard\n",
    "* `ticket` - Ticket Number\n",
    "* `fare` - Passenger Fare\n",
    "* `cabin` - Cabin\n",
    "* `embarked` - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "* `boat` - Lifeboat (if survived)\n",
    "* `body` - Body number (if did not survive and body was recovered)\n",
    "* `home.dest` - Home/Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic dataframe'inin sütunlarını görelim.\n",
    "titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e287f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic dataframe'inin son on örneğini inceleyelim.\n",
    "titanic.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad199226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic dataframe'inin sütunlarının barındırdığı verilerin türünü ve sayısını görelim.\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d31fdb",
   "metadata": {},
   "source": [
    "***\n",
    "***age* feature'u, içerisinde birbirinden farklı tipte veriler barındırdığı için `object` tipinde karşımıza çıkıyor**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f6d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab7604b",
   "metadata": {},
   "source": [
    "## *read_csv()* Metodunun ',' İşaretinin Ayırıcı Olarak Kullanılmadığı Veri Setlerine Uygulanması\n",
    "\n",
    "* `netflix_titles.csv` dosyası içerisindeki veriler, pipe (`|`) karakteri ile birbirinden ayrılmış durumda. `read_csv()` metodunu kullanırken `sep=\"|\"` şeklinde bir parametre kullanarak bu dosyadaki verileri import edebiliriz.\n",
    "\n",
    "\n",
    "* Bununla birlikte, Netflix veri seti ilk sütununda bir index sütunu bulundurur. Bu sütunun dataframe'e aktarabilmek adına `index_col=0` parametresi kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `netflix_titles.csv` veri setini import edelim.\n",
    "netflix = pd.read_csv(\"../data/netflix_titles.csv\", sep=\"|\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020239ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflix dataframe'i içerisindeki örnek sayısını, sütunları ve sütunların barındırdığı verilerin türünü inceleyelim.\n",
    "netflix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflix dataset'inin ilk 5 örneğini inceleyelim.\n",
    "netflix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a10fe8",
   "metadata": {},
   "source": [
    "***\n",
    "## Yeni Sütun İsimleri Eklemek\n",
    "\n",
    "\n",
    "`read_csv` metodunu, `names` parametresi ile birlikte kullanarak kendi hazırladığımız sütun isimlerini dataframe'e aktarabiliriz. Bununla birlikte **`header=0`** ifadesini de `read_csv` metoduna ekleyerek, orijinal sütun isimlerinin orijinal dosyadanın ilk satırında olduğunu ve karışıklık yaşanmaması adına bu satırın görmezden gelinmesi gerektiğini belirtebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Üzerinde çalışacağımız veri setini inceleyelim\n",
    "pd.read_csv(\"../data/nst-est2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sütun isimlerini değiştirmek için yeni isimleri bir liste içerisinde tutalım\n",
    "names = ['sumlev', 'region', 'division', 'state', 'name', 'census2010pop', 'estimatesbase2010', 'popestimate2010', 'popestimate2011', 'popestimate2012', 'popestimate2013', 'popestimate2014', 'popestimate2015', 'popestimate2016', 'popestimate2017', 'popestimate2018', 'popestimate2019', 'popestimate042020', 'popestimate2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Şimdi de yeni isimleri kullanarak veri setini inceleyelim\n",
    "pd.read_csv(\"../data/nst-est2020.csv\", names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75aed5",
   "metadata": {},
   "source": [
    "***\n",
    "**Dikkat ederseniz, dataframe'in sütunlarının ismimlerini belirlediğimiz isimlerle değiştirdiğimizde, orijinal veri setinin ilk örneğindeki sütun isimleri bir veri gibi davranarak dataframe'e dahil oluyor. Karışıklık olmaası adına bu durumu istemiyoruz. Bu nedenle yukarıda bahsedildiği gibi `header` parametresine `0` atayarak orijinal sütun isimlerinin korunmasını ancak görmezden gelinerek yeni sütun isimlerinin gösterilmesini sağlayacağız.**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setimizi yeni isimlerle ve düzenlenmiş halde import edelim\n",
    "state_pops = pd.read_csv(\"../data/nst-est2020.csv\", names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6502d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe'in ilk beş örneğini görelim.\n",
    "state_pops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10d9788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yukarıda da görüldüğü üzere amacımıza ulaştık.\n",
    "# Daha iyi anlamak için orijinal data frame'deki sütun isimlerinin değişip değişmediğine bakalım.\n",
    "pd.read_csv(\"../data/nst-est2020.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f866c391",
   "metadata": {},
   "source": [
    "***\n",
    "**Görüldüğü gibi orijinal dataframe'de herhangi bir değişiklik olmadı. Buradan anlıyoruz ki sütün isimlerini `names` parametresi ile değiştirken aslında sütun isimlerini belirlenen isimlerle göstermiş oluyoruz ya da yeni sütun isimlerine sahip bir dataframe oluştururuz. Bu işlem, veri üzerinde çalışırken kafa karışıklılığı yaratmamak adına kullanılıp işleri hızlandırabilir.**\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
